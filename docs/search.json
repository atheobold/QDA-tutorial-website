[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Coding Code: Qualitative Methods for Investigating Data Science Skills",
    "section": "",
    "text": "Students are creative thinkers, and their code provides a window into their learning process. A qualitative analysis of a student’s code can provide insight into their creative process and collective learning process, rather than focusing solely on whether the code is executable. Moreover, qualitative methods allow for the comparison across students’ code to identify learning trajectories that may exist and potential growth points."
  },
  {
    "objectID": "blog.html#structure-of-tutorial",
    "href": "blog.html#structure-of-tutorial",
    "title": "A Guide to Qualitatively Analyzing Computing Code",
    "section": "Structure of Tutorial",
    "text": "Structure of Tutorial\nThe pages of this website correspond to different aspects of the analysis process as pictured above.\n\nI discuss how one selects a unit of analysis\nI outline how descriptive codes are created\nI walk through how codes can be collapsed into emergent themes\nI describe how student interviews allowed me to dig deeper into the themes that emerged\nI talk through how to make comparisons across individual’s themes"
  },
  {
    "objectID": "analysis-framework.html",
    "href": "analysis-framework.html",
    "title": "Step 1: Selecting a Unit of Analysis",
    "section": "",
    "text": "The process of data analysis begins by identifying segments in your data set that are responsive to your research questions” (Merriam and Tisdell 2016). These segments form the units of analysis (UOA), which can be as small as a single word or as large as an entire report. Collectively, themes identified in these units will answer a study’s research question(s). Lincoln and Guba (1985) suggest that a unit of analysis ought to meet two criteria. First, the UOA should be heuristic, that is, it should reveal information pertinent to the study and move the reader to think beyond the singular piece of information. Second, the unit should be the smallest piece of information about something that can stand by itself.” Moreover, a UOA must be interpretable in the absence of any additional information, requiring only that the reader have a broad understanding of the study context.\nFor qualitative investigations of students’ computing code, we propose researchers consider the Block Model as an analytical lens. The Block Model is an educational framework that supports the analysis of the different aspects of a computer program."
  },
  {
    "objectID": "analysis-framework.html#block-model",
    "href": "analysis-framework.html#block-model",
    "title": "Step 1: Selecting a Unit of Analysis",
    "section": "Block Model",
    "text": "Block Model\nIn the Block Model (Schulte 2008), each row represents one selection for the unit of analysis and each column speaks to a different lens of analysis. To decide between the 12 possible options a researcher must consider the context of inquiry. This context dictates the scale of the code that deserves attention.\n\nSchulte, C. 2008. “Block Model: An Educational Model of Program Comprehension as a Tool for a Scholarly Approach to Teaching.” In Proceedings of the Fourth International Workshop on Computing Education Research, 149–60. Sydney, Australia: Association of Computing Machinery; Association of Computing Machinery.\nAn investigation focusing on the broader purpose or structure of a program requires a researcher to zoom out and consider a program’s macrostructure. Whereas, studying individual pieces or segments of a program requires a researcher to zoom in on the atoms or the blocks.\n\n\n\n\n\n\n\n\n\nLevel\n\nDimension\n\n\n\n\n\n\nText Surface\nProgram Execution\nFunction / Purpose\n\n\nMacrostructure\nUnderstanding the overall structure of the program text.\nUnderstanding the algorithm underlying a program.\nUnderstanding the goal/purpose of the program (in the context at hand).\n\n\nRelationships\nRelations & references between blocks (e.g. method calls, object creation, accessing data…)\nSequence of method calls, object sequence diagrams.\nUnderstanding how subgoals are related to goals, how function is achieved by subfunctions.\n\n\nBlocks\nRegions of interest (ROI) that syntactically or semantically build a unit\nOperations of a block, a method, or a ROI (chunk from a set of statements).\nUnderstanding the function of a block, seen as a subgoal.\n\n\nAtoms\nLanguage elements\nOperation of a statement.\nFunction of a statement: its purpose can only be understood in a context."
  },
  {
    "objectID": "analysis-framework.html#analytical-framework-used",
    "href": "analysis-framework.html#analytical-framework-used",
    "title": "Step 1: Selecting a Unit of Analysis",
    "section": "Analytical Framework Used",
    "text": "Analytical Framework Used\nFor the study I will walk you through, I chose to use atoms as my unit of study. An atom constitutes a language element in a program, and can thus have a variety of grain sizes, from characters to words to statements. I chose to have my “atom” be a syntactic statement of R code. A syntactic statement is a line, or set of lines, which constitute the smallest syntactically valid statement of code. Some statements of code were completed in a single line, while others took multiple lines.**As R belongs to the family of “curly bracket” programming languages, influenced by C, R has a syntax which defines statements using curly brackets ({}), many of these statements are introduced by identifiers such as if(), for(), or while().\nFor this study, I selected the program execution as my dimension of analysis. This dimension focuses on the action of each statement, or more specifically what operation it carries out. I chose this dimension as I was interested in understanding what data science skills students were employing within their projects. A program execution lens views these skills as distinct rather than considering their role in the broader function of the program."
  },
  {
    "objectID": "descriptive-codes.html",
    "href": "descriptive-codes.html",
    "title": "Step 2: Descriptive Codes",
    "section": "",
    "text": "The second step in the qualitative analysis is creating qualitative codes for each unit of analysis (UOA).\nThe process of coding in qualitative research, where a researcher makes notes next to each UOA that are potentially relevant to addressing the research question. Codes act as labels, assigning “symbolic meaning” to each UOA (Miles, Huberman, and Saldaña 2020). In our context, each line of R code is a UOA, which is why we are “coding code.”\nThe initial qualitative codes assigned to the units of analysis can be thought of as the “first cycle codes.” There are over 25 different methods for creating first cycle codes, each with a particular focus and purpose. In our paper, we discuss two specific methods of coding we believe are most relevant to investigating computing code: descriptive coding and in vivo coding.\nFor this research, I chose to use descriptive codes as I sought to describe the computing skills students were using in their research project. With in vivo coding, these descriptions would be required to take on the voice (code) of each student, which I felt constrained the possible descriptions available to me."
  },
  {
    "objectID": "descriptive-codes.html#student-a-descriptive-codes",
    "href": "descriptive-codes.html#student-a-descriptive-codes",
    "title": "Step 2: Descriptive Codes",
    "section": "Student A – Descriptive Codes",
    "text": "Student A – Descriptive Codes\nIf you are interested in seeing the original R script file from Student A, you can find that here."
  },
  {
    "objectID": "descriptive-codes.html#student-b-descriptive-codes",
    "href": "descriptive-codes.html#student-b-descriptive-codes",
    "title": "Step 2: Descriptive Codes",
    "section": "Student B – Descriptive Codes",
    "text": "Student B – Descriptive Codes\nIf you are interested in seeing the original R script file from Student A, you can find that here."
  },
  {
    "objectID": "themes.html",
    "href": "themes.html",
    "title": "Step 3: Discovering Emergent Themes",
    "section": "",
    "text": "Categories should span multiple codes that were previously identified. These categories “capture some recurring pattern that cuts across your data” (Merriam and Tisdell 2016, 207). Merriam and Tisdell (2016) suggest this process of discovering themes from codes feels somewhat like constantly transitioning one’s perspective of a forest, from looking at the “trees” (codes) to the “forest” (themes) and back to the trees."
  },
  {
    "objectID": "themes.html#discoving-themes",
    "href": "themes.html#discoving-themes",
    "title": "Step 3: Discovering Emergent Themes",
    "section": "Discoving Themes",
    "text": "Discoving Themes\nAs I looked over my descriptive codes, I asked myself what these codes tell me about the nature of the data science skills students used in their projects. Some themes immediately jumped out at me, whereas others took a bit of time to mull over. I’ll walk you through my process below.\n\n“Obvious” Themes\nThere were two themes I expected to see due to the nature of the project and the requirements stipulated by the professor. For their project, students were expected to (1) use an analysis strategy learned in the course and (2) create a visualization to accompany any analysis and resulting discussion. Thus, I expected themes of “Data Model” and “Data Visualization” to emerge from the data.\nFrom my own experiences, I also expected that students would need to perform some aspect of data wrangling to prepare their data for analysis. The data students used for their project were from their own research, so, although I knew data wrangling would play some role, I was unsure what type of tasks might appear in the codes.\n\n\nEmergent Themes\nWhile I was looking over the data wrangling tasks students performed in their projects, I noticed the techniques used required knowledge of different data structures. The implementation of some tasks was fairly uniform (select column from dataframe using $ operator), whereas other tasks were highly variable. Data filtering was sometimes done with the subset() function, which requires little explicit knowledge of data structures. However, other times this filtering was carried out using the [] / extraction operator, a technique which requires an understanding of how extraction differs across different data structures (e.g., dataframes, matrices, vectors).\nI also noticed while looking at the R code for the “Data Model” and “Data Visualization” themes that certain statements of code included some knowledge (or lack thereof) regarding the R Environment. The most obvious statement that evoked this theme used with() to temporarily attach a dataframe. There were, however, other statements that also fit into this theme, such as function arguments being bypassed, sourcing in an external R script, loading in datasets, and loading in packages.\nWithin the themes of “Data Model” and “Data Wrangling,” I uncovered an additional theme which speaks to the efficiency of a statement of code. The notion of efficiency came to me from the “don’t repeat yourself” principle (Wilson et al. 2014), which recommends scientists modularize their code rather than copying and pasting and re-use their code instead of rewriting it (p. 2). Thus, I considered code which adhered to these practices “efficient” and code which did not adhere to these practices “inefficient.”\n\nWilson, Greg, D. A. Aruliah, C. Titus Brown, Neil P. Chue Hong, Matt Davis, Richard T. Guy, Steven H. D. Haddock, et al. 2014. “Best Practices for Scientific Computing.” PLOS Biology 12 (1): e1001745.\nThe final theme I discovered were statements of code whose purpose was more for a student’s workflow than anything else. Code comments were my first indication of this theme, where students used code comments to create sections of code or flag what was happening in a particular line / lines of code. I expanded this theme to include statements of code which inspect some characteristic of an object (e.g., structure of a datafame, names of a dataframe, summary of a linear model)."
  },
  {
    "objectID": "themes.html#assigning-descriptive-codes-to-themes",
    "href": "themes.html#assigning-descriptive-codes-to-themes",
    "title": "Step 3: Discovering Emergent Themes",
    "section": "Assigning Descriptive Codes to Themes",
    "text": "Assigning Descriptive Codes to Themes\n\n\nFor each of the themes outlined above, the associated “atoms” / statements of code are listed. Keep in mind one statement can apply to two themes! For example, the code\nlinearAnterior <- lm(PADataNoOutlier$Lipid ~ PADataNoOutlier$PSUA)\napplies to three themes. First and foremost, this code uses lm() to fit a linear regression model to the data (data model). Second, in order to fit the data model, the student uses data wrangling to select the variables of interest(PADataNoOutlier$Lipid, PADataNoOutlier$PSUA). Finally, this code does not make use of the data = argument built in to lm(), which implies a lack of understanding of the function and thus the R environment.\n\nData Model\n\n\n\nDefinition: Statements of code whose purpose is to create a statistical model from data.\n\n\n\n\n\n\n\n\n\nData Visualization\n\n\n\nDefinition: Statements of code whose purpose is to visualize relationships between variables\nSub-themes\n\nscatterplot\nadding lines to plot\ndifferentiated colors\nincluding a legend\nchanging plotting environment\nmodifying axis labels / plot titles\n\n\n\n\n\n\n\n\n\n\nData Wrangling\n\n\n\nDefinition: Statements of code whose purpose is to prepare a dataset for analysis and / or visualization\nSub-themes\n\nselecting columns\nfiltering rows / observations\nmutating variables\nsummarizing variables\nsummarizing variables across groups\n\n\n\n\n\n\n\n\n\n\nData Structures\n\n\n\nDefinition: An statement of code which explicitly calls upon attributes of a data structure (e.g., dataframe, matrix, vector)\n\n\n\n\n\n\n\n\n\nR Environment\n\n\n\nDefinition: A statement of code which calls on explicit aspects of the R environment\n\n\n\n\n\n\n\n\n\nEfficiency / Inefficiency\n\n\n\nDefinition: A statement of code which adheres to the “don’t repeat yourself” principle\n\n\n\n\n\n\n\n\n\nWorkflow\n\n\n\nDefinition: A statement of code which facilitates a smooth execution of a working process"
  },
  {
    "objectID": "digging-deeper.html#student-b",
    "href": "digging-deeper.html#student-b",
    "title": "Step 4: Digging Deeper",
    "section": "Student B",
    "text": "Student B"
  },
  {
    "objectID": "comparing-students.html",
    "href": "comparing-students.html",
    "title": "Optional: Comparing Across Students",
    "section": "",
    "text": "Efficiency / Inefficiency\n\n\n\n\n\n\n\n\n\n\n\n\n\nReadability\n\n\n\n\n\n\nReproducibility"
  },
  {
    "objectID": "bio.html",
    "href": "bio.html",
    "title": "Allison Theobold",
    "section": "",
    "text": "Allison Theobold is an Associate Professor of Statistics at California Polytechnic University in beautiful San Luis Obispo, California. Allison’s work focuses on innovation in statistics and data science education, with an emphasis on equitable pedagogy and learning trajectories. Allison is also interested in exploring pedagogical approaches for enhancing retention of under-represented students in STEM, including creating inclusive discoursive spaces and equitable group collaborations."
  },
  {
    "objectID": "bio.html#education",
    "href": "bio.html#education",
    "title": "Allison Theobold",
    "section": "Education",
    "text": "Education\nPhD in Statistics, Montana State University — Bozeman, MT\nM.S. in Statistics, Montana State University — Bozeman, MT\nB.S. in Mathematics, Colorado Mesa University — Grand Junction, CO\nB.B.A. in Economics, Colorado Mesa University — Grand Junction, CO"
  },
  {
    "objectID": "bio.html#publications",
    "href": "bio.html#publications",
    "title": "Allison Theobold",
    "section": "Publications",
    "text": "Publications\nTheobold, A. S. & Williams. “I watched as he put things on the paper”: A Feminist View of Mathematical Discourse, Psychology of Mathematics Education North America (PME-NA) Conference.\nAmal Abdel-Ghani, Kelly Bodwin, Amelia McNamara, Allison Theobold, and Ian Flores Siaca (2022). “Looks okay to me”: A study of best practice in data analysis code review, International Conference on Teaching Statistics (ICOTS) Conference.\nTheobold, A. (2021). Oral Exams: A More Meaningful Assessment of Statistical Understanding}, Journal of Statistics and Data Science Education, Brief Commentary.\nTheobold, A. S. & Williams, D. A. (2021). Discourse Patterns in a Small Group “Collaboration”: The Case of Uma and Sean. In Karunakaran, S. S. & Higgins, A. (Eds.), 2021 Research in Undergraduate Mathematics Education Reports (pp. 324-331).\nTheobold, A.}, Hancock, S., & Mannheimer, S. (2021). Designing Data Science Workshops for Data-Intensive Environmental Science Research}, Journal of Statistics Education, 29(sup1), S83-S94.\nTheobold, A. and Hancock, S. (2019). How Environmental Science Graduate Students Acquire Statistical Computing Skills}, Statistics Education Research Journal, 18(2), 68-85."
  }
]